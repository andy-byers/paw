// Copyright (c) 2024, The paw Authors. All rights reserved.
// This source code is licensed under the MIT License, which can be found in
// LICENSE.md. See AUTHORS.md for a list of contributor names.
//
// ebnf.paw


//
// File I/O
//

use io;

const CHUNK_SIZE: int = 1 << 12;

fn read_to_string(path: str) -> io::Result<str> {
    let file = io::File::open(path, "r")?;

    let result = "";
    loop {
        result += match file.read(CHUNK_SIZE)? {
            "" => return io::Result::Ok(result),
            s => s,
        };
    }
}


//
// Tokenizer
// 

fn is_space(c: str) -> bool {
    c == " " || c == "\t" || c == "\f" || c == "\v" || c == "\r" || c == "\n"
}

fn is_alpha(c: str) -> bool {
    c == "a" || c == "b" || c == "c" || c == "d" || c == "e" || c == "f" || c == "g" || c == "h" || c == "i" || c == "j" || c == "k" || c == "l" || c == "m" || c == "n" || c == "o" || c == "p" || c == "q" || c == "r" || c == "s" || c == "t" || c == "u" || c == "v" || c == "w" || c == "x" || c == "y" || c == "z" || c == "A" || c == "B" || c == "C" || c == "D" || c == "E" || c == "F" || c == "G" || c == "H" || c == "I" || c == "J" || c == "K" || c == "L" || c == "M" || c == "N" || c == "O" || c == "P" || c == "Q" || c == "R" || c == "S" || c == "T" || c == "U" || c == "V" || c == "W" || c == "X" || c == "Y" || c == "Z"
}

fn is_alnum(c: str) -> bool {
    is_alpha(c) || c == "0" || c == "1" || c == "2" || c == "3" || c == "4" || c == "5" || c == "6" || c == "7" || c == "8" || c == "9"
}

inline struct SourceLoc {
    pub line: int,
    pub column: int,

    pub fn to_string(self) -> str {
        "\{self.line}:\{self.column}"
    }
}

struct Scanner {
    token: Token,
    location: SourceLoc,
    source: str,
    index: int,
    

    pub fn new(source: str) -> Self {
        let location = SourceLoc{line: 0, column: 0};
        let scanner = Self{
            token: Token{kind: TokenKind::Eof, data: "", location},
            index: 0, 
            location,
            source, 
        };
        scanner.skip();
        scanner
    }

    pub fn location(self) -> SourceLoc {
        self.location
    }

    pub fn token(self) -> Token {
        self.token
    }

    pub fn skip(self) {
        self.token = self.advance();
    }

    fn get_char(self) -> str {
        if self.index < #self.source {
            let c = self.source[self.index];
            if (c == '\r' || c == '\n') {
                self.location.line += 1;
                self.location.column = 0;
            }
            c
        } else {
            ""
        }
    }

    fn peek_char(self, n: int) -> str {
        if self.index < #self.source - n {
            self.source[self.index + n]
        } else {
            ""
        }
    }

    fn skip_char(self) {
        self.location.column += 1;
        self.index += 1;
    }

    fn advance(self) -> Token {
        self.skip_whitespace();

        let loc = self.location;
        let kind = match self.get_char() {
            '"' => return self.scan_string(),
            c if is_alpha(c) || c == "_" => return self.scan_ident(),
            "(" if self.peek_char(1) == "*" => return self.scan_comment(),
            "." if self.peek_char(1) == "." => {
                self.skip_char(); // skip "."
                TokenKind::DotDot
            },

            "|" => TokenKind::Pipe,
            "." => TokenKind::Dot,
            "=" => TokenKind::Equals,
            "(" => TokenKind::LeftParen,
            ")" => TokenKind::RightParen,
            "[" => TokenKind::LeftSquare,
            "]" => TokenKind::RightSquare,
            "{" => TokenKind::LeftCurly,
            "}" => TokenKind::RightCurly,
            "-" => TokenKind::Hyphen,
            "" => TokenKind::Eof,

            c => TokenKind::Error(TokenErrorKind::UnknownToken),
        };
        self.skip_char();
        self.new_token(loc, kind, "")
    }

    fn skip_whitespace(self) {
        loop {
            match self.get_char() {
                " " | "\r" | "\n" | "\t" | "\f" | "\v" => self.skip_char(),
                _ => break,
            }
        }
    }

    fn new_token(self, location: SourceLoc, kind: TokenKind, data: str) -> Token {
        Token{data: data, kind, location}
    }

    fn new_error(self, location: SourceLoc, kind: TokenErrorKind, data: str) -> Token {
        self.new_token(location, TokenKind::Error(kind), data)
    }

    fn scan_comment(self) -> Token {
        self.skip_char(); // skip "("
        self.skip_char(); // skip "*"

        let loc = self.location;
        let data = "";

        loop {
            match self.get_char() {
                // reached EOF: block comment was not terminated
                "" => return self.new_error(loc, TokenErrorKind::UnterminatedComment, data),

                "*" if self.peek_char(1) == ")" => {
                    self.skip_char(); // skip "*"
                    self.skip_char(); // skip ")"
                    return self.new_token(loc, TokenKind::Comment, data);
                },

                c => {
                    self.skip_char();
                    data += c;
                },
            }
        }
    }

    fn scan_ident(self) -> Token {
        let loc = self.location;
        let data = "";

        loop {
            let c = self.get_char();
            if is_alnum(c) || c == "_" {
                self.skip_char();
                data += c; 
            } else {
                return self.new_token(loc, TokenKind::Ident, data);
            }
        }
    }

    fn scan_string(self) -> Token {
        self.skip_char(); // '"'

        let loc = self.location;
        let data = "";

        loop {
            match self.get_char() {
                '\\' => {
                    self.skip_char(); // skip '\\'
                    match self.get_char() {
                        '\\' => data += '\\',
                        '"' => data += '"',
                        '/' => data += '/',
                        'b' => data += '\b',
                        'v' => data += '\v',
                        'f' => data += '\f',
                        'n' => data += '\n',
                        'r' => data += '\r',
                        't' => data += '\t',
                        _ => break,
                    }
                },
                '"' => {
                    self.skip_char(); // skip '"'
                    return self.new_token(loc, TokenKind::String, data);
                },
                "" | '\r' | '\n' => break,
                c => data += c,
            }
            self.skip_char();
        }

        self.new_error(loc, TokenErrorKind::UnterminatedString, data)
    }
}

inline struct Token {
    pub location: SourceLoc,
    pub kind: TokenKind,
    pub data: str,

    pub fn to_string(self) -> str {
        match self.kind {
            TokenKind::Ident => self.data,
            TokenKind::String => '"\{self.data}"',
            TokenKind::Comment => "(* \{self.data} *)",
            TokenKind::LeftParen => "(",
            TokenKind::RightParen => ")",
            TokenKind::LeftSquare => "[",
            TokenKind::RightSquare => "]",
            TokenKind::LeftCurly => "{",
            TokenKind::RightCurly => "}",
            TokenKind::Pipe => "|",
            TokenKind::Equals => "=",
            TokenKind::Hyphen => "-",
            TokenKind::DotDot => "..",
            TokenKind::Dot => ".",
            TokenKind::Eof => "",

            TokenKind::Error(e) => e.to_string(),
        }
    }
}

inline enum TokenKind {
    Ident,
    String,
    Comment,
    LeftParen,
    RightParen,
    LeftSquare,
    RightSquare,
    LeftCurly,
    RightCurly,
    Pipe,
    Equals,
    Hyphen,
    DotDot,
    Dot,

    Eof,
    Error(TokenErrorKind),

    pub fn to_string(self) -> str {
        match self {
            TokenKind::Ident => "<ident>",
            TokenKind::String => "<string>",
            TokenKind::Comment => "<comment>",
            TokenKind::LeftParen => "(",
            TokenKind::RightParen => ")",
            TokenKind::LeftSquare => "[",
            TokenKind::RightSquare => "]",
            TokenKind::LeftCurly => "{",
            TokenKind::RightCurly => "}",
            TokenKind::Pipe => "|",
            TokenKind::Equals => "=",
            TokenKind::Hyphen => "-",
            TokenKind::DotDot => "..",
            TokenKind::Dot => ".",
            TokenKind::Eof => "",
            TokenKind::Error(e) => e.to_string(),
        }
    }

    pub fn equals(self, k: TokenKind) -> bool {
        match (self, k) {
            (TokenKind::Ident, TokenKind::Ident)
            | (TokenKind::String, TokenKind::String)
            | (TokenKind::Comment, TokenKind::Comment)
            | (TokenKind::LeftParen, TokenKind::LeftParen)
            | (TokenKind::RightParen, TokenKind::RightParen)
            | (TokenKind::LeftSquare, TokenKind::LeftSquare)
            | (TokenKind::RightSquare,TokenKind::RightSquare)
            | (TokenKind::LeftCurly,  TokenKind::LeftCurly)
            | (TokenKind::RightCurly, TokenKind::RightCurly)
            | (TokenKind::Pipe, TokenKind::Pipe)
            | (TokenKind::Equals, TokenKind::Equals)
            | (TokenKind::Hyphen, TokenKind::Hyphen)
            | (TokenKind::DotDot, TokenKind::DotDot)
            | (TokenKind::Dot, TokenKind::Dot)
            | (TokenKind::Eof, TokenKind::Eof) => true,
            (TokenKind::Error(a), TokenKind::Error(b)) => a.equals(b),
            _ => false,
        }
    }
}

inline enum TokenErrorKind {
    UnknownToken,
    UnterminatedString,
    UnterminatedComment,
    InvalidEscapeChar,

    pub fn to_string(self) -> str {
        match self {
            TokenErrorKind::UnknownToken => "unknown token",
            TokenErrorKind::UnterminatedString => "unterminated string",
            TokenErrorKind::UnterminatedComment => "unterminated comment",
            TokenErrorKind::InvalidEscapeChar => "invalid escape char",
        }
    }

    pub fn equals(self, k: TokenErrorKind) -> bool {
        match (self, k) {
            (TokenErrorKind::UnknownToken, TokenErrorKind::UnknownToken)
            | (TokenErrorKind::UnterminatedString, TokenErrorKind::UnterminatedString)
            | (TokenErrorKind::UnterminatedComment, TokenErrorKind::UnterminatedComment)
            | (TokenErrorKind::InvalidEscapeChar, TokenErrorKind::InvalidEscapeChar) => true,
            _ => false,
        }
    }
}


//
// Parser
//

type ParseResult<T> = Result<T, ParseError>;

inline struct ParseError {
    pub kind: ParseErrorKind,
    pub location: SourceLoc,

    pub fn to_string(self) -> str {
        "\{self.location}: \{self.kind}"
    }
}

inline enum ParseErrorKind {
    UnterminatedComment,
    UnterminatedString(str),

    ExpectedToken(TokenKind, Token),
    UnexpectedToken(Token),

    pub fn to_string(self) -> str {
        match self {
            ParseErrorKind::UnterminatedString(s) => 'unterminated string "\{s}"',
            ParseErrorKind::UnterminatedComment => "unterminated comment",
            ParseErrorKind::ExpectedToken(k, t) => 'expected token "\{k}" but have "\{t}"',
            ParseErrorKind::UnexpectedToken(t) => 'unexpected token "\{t}"',
        }
    }
}

struct Grammer {
    pub productions: [Production],
    
    pub fn new(productions: [Production]) -> Self {
        Self{productions}
    }

    pub fn to_string(self) -> str {
        let result = "";
        for p in self.productions {
            result += "\{p}\n";
        }
        result
    }
}

inline struct Production {
    pub ident: str,
    pub expr: Expression,

    pub fn to_string(self) -> str {
        "\{self.ident} = \{self.expr} ."
    }
}

inline struct Expression {
    pub alts: [Alternative],

    pub fn to_string(self) -> str {
        let result = "";
        for a in self.alts {
            if #result > 0 { result += " | "; }
            result += a.to_string();
        }
        result
    }
}

inline struct Alternative {
    pub terms: [Term],

    pub fn to_string(self) -> str {
        let result = "";
        for t in self.terms {
            if #result > 0 { result += " "; }
            result += t.to_string();
        }
        result
    }
}

enum Term {
    Ident(str),
    Terminal(str),
    Range(str, str),
    Exception(Term, Term),
    Group(Expression),
    Option(Expression),
    Repetition(Expression),

    pub fn to_string(self) -> str {
        match self {
            Term::Ident(data) => data,
            Term::Terminal(data) => '"\{data}"',
            Term::Range(lhs, rhs) => '"\{lhs}".."\{rhs}"',
            Term::Exception(lhs, rhs) =>  "\{lhs} - \{rhs}",
            Term::Group(expr) => "(\{expr})",
            Term::Option(expr) =>  "[\{expr}]",
            Term::Repetition(expr) =>  "{\{expr}}",
        }
    }
}

struct Parser {
    pub fn new() -> Self {
        Self
    }

    pub fn parse(self, s: Scanner) -> ParseResult<Grammer> {
        let result = [];
        while !self.is_finished(s) {
            result.push(self.production(s)?);
        }
        ParseResult::Ok(Grammer::new(result))
    }

    fn is_finished(self, s: Scanner) -> bool {
        match self.token(s).kind {
            TokenKind::Eof => true,
            _ => false,
        }
    }

    fn token(self, s: Scanner) -> Token {
        loop {
            let t = s.token();
            match t.kind {
                TokenKind::Comment => s.skip(),
                _ => return t,
            }
        }
    }

    fn check(self, s: Scanner, k: TokenKind) -> bool {
        self.token(s).kind.equals(k)
    }

    fn check_next(self, s: Scanner, k: TokenKind) -> bool {
        if self.check(s, k) {
            s.skip();
            true
        } else {
            false
        }
    }

    fn expect(self, s: Scanner, k: TokenKind) -> ParseResult<Token> {
        match self.token(s) {
            t if t.kind.equals(k) => ParseResult::Ok(t),
            t => Self::expected_token(s, k, t),
        }
    }

    fn expect_next(self, s: Scanner, k: TokenKind) -> ParseResult<Token> {
        let token = self.expect(s, k)?;
        s.skip();
        ParseResult::Ok(token)
    }

    fn unexpected_token<T>(s: Scanner, t: Token) -> ParseResult<T> {
        ParseResult::Err(ParseError{
            kind: ParseErrorKind::UnexpectedToken(t), 
            location: s.location(),
        })
    }

    fn expected_token<T>(s: Scanner, want: TokenKind, have: Token) -> ParseResult<T> {
        ParseResult::Err(ParseError{
            kind: ParseErrorKind::ExpectedToken(want, have), 
            location: s.location(),
        })
    }

    fn production(self, s: Scanner) -> ParseResult<Production> {
        let ident = self.expect_next(s, TokenKind::Ident)?;
        self.expect_next(s, TokenKind::Equals)?;
        let expr = self.expression(s)?;
        self.expect_next(s, TokenKind::Dot)?;

        ParseResult::Ok(Production{ident: ident.data, expr})
    }

    fn expression(self, s: Scanner) -> ParseResult<Expression> {
        let alts = self.alternatives(s)?;
        ParseResult::Ok(Expression{alts})
    }

    fn alternatives(self, s: Scanner) -> ParseResult<[Alternative]> {
        let result = [];
        loop {
            result.push(self.alternative(s)?);
            if self.check(s, TokenKind::Pipe) {
                s.skip(); // skip "|"
            } else {
                return ParseResult::Ok(result);
            }
        }
    }

    fn alternative(self, s: Scanner) -> ParseResult<Alternative> {
        let terms = self.terms(s)?;
        ParseResult::Ok(Alternative{terms})
    }

    fn terms(self, s: Scanner) -> ParseResult<[Term]> {
        let result = [];
        loop {
            let term = self.term(s)?;
            result.push(term);

            let t = self.token(s);
            match t.kind {
                TokenKind::Dot 
                | TokenKind::Pipe
                | TokenKind::RightParen
                | TokenKind::RightSquare
                | TokenKind::RightCurly 
                | TokenKind::Eof => break,
                _ => (),
            }
        }
        if #result == 0 {
            assert(false);
            //return Self::expected_term();
        }
        ParseResult::Ok(result)
    }

    fn term(self, s: Scanner) -> ParseResult<Term> {
        let token = self.token(s);
        let term = match token.kind {
            TokenKind::Ident => self.new_ident(s, token),
            TokenKind::String => self.terminal_or_range(s, token)?,
            TokenKind::LeftParen => self.grouping(s)?,
            TokenKind::LeftSquare => self.option(s)?,
            TokenKind::LeftCurly => self.repetition(s)?,
            _ => return Self::unexpected_token(s, token),
        };
        let term = if self.check(s, TokenKind::Hyphen) {
            self.exception(s, term)?
        } else {
            term 
        };
        ParseResult::Ok(term) 
    }

    fn new_ident(self, s: Scanner, t: Token) -> Term {
        s.skip(); // skip identifier
        Term::Ident(t.data)
    }

    fn terminal_or_range(self, s: Scanner, t: Token) -> ParseResult<Term> {
        s.skip(); // skip string
        if self.check(s, TokenKind::DotDot) {
            s.skip(); // skip ".."
            let t2 = self.expect_next(s, TokenKind::String)?;
            ParseResult::Ok(Term::Range(t.data, t2.data))
        } else {
            ParseResult::Ok(Term::Terminal(t.data))
        }
    }

    fn exception(self, s: Scanner, lhs: Term) -> ParseResult<Term> {
        s.skip(); // skip "-"
        let rhs = self.term(s)?;
        ParseResult::Ok(Term::Exception(lhs, rhs))
    }

    fn grouping(self, s: Scanner) -> ParseResult<Term> {
        s.skip(); // skip "("
        let expr = self.expression(s)?;
        self.expect_next(s, TokenKind::RightParen)?;
        ParseResult::Ok(Term::Group(expr))
    }

    fn option(self, s: Scanner) -> ParseResult<Term> {
        s.skip(); // skip "["
        let expr = self.expression(s)?;
        self.expect_next(s, TokenKind::RightSquare)?;
        ParseResult::Ok(Term::Option(expr))
    }

    fn repetition(self, s: Scanner) -> ParseResult<Term> {
        s.skip(); // skip "{"
        let expr = self.expression(s)?;
        self.expect_next(s, TokenKind::RightCurly)?;
        ParseResult::Ok(Term::Repetition(expr))
    }
}

fn foreach_ident(expr: Expression, callback: fn(str)) {
    for Alternative{terms} in expr.alts {
        for t in terms {
            match t {
                Term::Group(e) | Term::Option(e) | Term::Repetition(e) 
                    => foreach_ident(e, callback),
                Term::Ident(s) => callback(s),
                _ => (),
            }
        }
    }
}

fn analyze_grammer(ctx: Context, g: Grammer) -> Result<[str: Expression], str> {
    let builtins = ctx.builtins;
    let idents = [:];
    let result = [:];

    for Production{ident, expr} in g.productions {
        if result.contains(ident) {
            return Result::Err('duplicate identifier "\{ident}"');
        }
        if builtins.contains(ident) {
            return Result::Err('definition of builtin identifier "\{ident}"');
        }
        result[ident] = expr;

        foreach_ident(expr, |ident: str| idents[ident] = ());
    }
    for ident in idents {
        if !result.contains(ident) && !builtins.contains(ident) {
            return Result::Err('missing identifier "\{ident}"');
        }
    }
    Result::Ok(result)
}

inline enum Verbosity {
    Quiet, // no messages
    Normal, // errors only
    Verbose, // errors and info

    pub fn should_print_error(self) -> bool {
        match self {
            Verbosity::Quiet => false,
            _ => true,
        }
    }

    pub fn should_print_info(self) -> bool {
        match self {
            Verbosity::Verbose => true,
            _ => false,
        }
    }
}

struct Context {
    pub verbosity: Verbosity,
    pub program_name: str,
    pub builtins: [str: ()],

    pub fn new(program_name: str) -> Self {
        Self{
            verbosity: Verbosity::Normal,
            builtins: ["UNICODE_CODEPOINT": ()],
            program_name, 
        }
    }

    pub fn info(self, msg: str) {
        if self.verbosity.should_print_info() {
            print("\{msg}\n");
        }
    }

    pub fn error(self, msg: str) {
        if self.verbosity.should_print_error() {
            self.help(); // display help message
            print("\{self.program_name}: error: \{msg}\n");
        }
    }

    pub fn help(self) {
        self.info("paw \{self.program_name} PATH"
            + "=========================================="
            + "PATH: Path to file containing EBNF grammer");
    }
}

const SUCCESS: int = 0;
const FAILURE: int = 1;


pub fn test() -> int {
    let args = ["ebnf", "../../test.ebnf"];
//pub fn main(args: [str]) -> int {
    let ctx = Context::new(args.get_or(0, "ebnf"));

    let path = if #args < 2 {
        ctx.error("missing PATH argument");
        return FAILURE;
    } else {
        args[1]
    };

    let source = match read_to_string(path) {
        io::Result::Ok(s) => s,
        io::Result::Err(e) => {
            ctx.error('unable to read EBNF file "\{path}" (\{e})');
            return FAILURE;
        },
    };

    let scanner = Scanner::new(source);

    // Parse the token stream into a tree describing the given grammer. If "Parser::parse()"
    // completes without encountering an error, then the EBNF is syntactically correct.
    let parser = Parser::new();
    let grammer = match parser.parse(scanner) {
        ParseResult::Ok(g) => g,
        ParseResult::Err(e) => {
            ctx.error("syntax error: \{e}");
            return FAILURE;
        }
    };

    // Ensure that the grammer is well-formed with respect to the EBNF rules.
    let m = match analyze_grammer(ctx, grammer) {
        Result::Ok(r) => r,
        Result::Err(e) => {
            ctx.error("validation error: \{e}");
            return FAILURE;
        },
    };

    print("\{grammer}\n");

    SUCCESS
}

